"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è —Ç–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –≤–∏–∂–∏–≤–∞–Ω–Ω—è –Ω–∞ –¢–∏—Ç–∞–Ω—ñ–∫—É.
–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î –æ–ø—Ç–∏–º–∞–ª—å–Ω—É –º–æ–¥–µ–ª—å (Good Fit) –∑ –Ω–æ—É—Ç–±—É–∫–∞ Chapter_3_Ov_Un.ipynb
"""

import pandas as pd
import numpy as np
import warnings
import pickle
import os
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder

warnings.filterwarnings('ignore')

def prepare_data():
    """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î —Ç–∞ –ø—ñ–¥–≥–æ—Ç–æ–≤–ª—é—î –¥–∞–Ω—ñ –¥–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è"""
    print("üö¢ –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –¥–∞—Ç–∞—Å–µ—Ç Titanic...")
    
    # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –¥–∞—Ç–∞—Å–µ—Ç
    url = "https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv"
    df = pd.read_csv(url)
    
    print(f"‚úÖ –î–∞—Ç–∞—Å–µ—Ç –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ! –ö—ñ–ª—å–∫—ñ—Å—Ç—å –∑–∞–ø–∏—Å—ñ–≤: {len(df)}")
    
    # –í–∏–±–∏—Ä–∞—î–º–æ –≤–∞–∂–ª–∏–≤—ñ –∫–æ–ª–æ–Ω–∫–∏
    df_clean = df[['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']].copy()
    
    # –ó–∞–ø–æ–≤–Ω—é—î–º–æ –ø—Ä–æ–ø—É—â–µ–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è –≤—ñ–∫—É –º–µ–¥—ñ–∞–Ω–æ—é
    df_clean = df_clean.fillna({'Age': df_clean['Age'].median()})
    
    # –ü–µ—Ä–µ—Ç–≤–æ—Ä—é—î–º–æ —Å—Ç–∞—Ç—å –Ω–∞ —á–∏—Å–ª–∞ (Male=1, Female=0)
    le = LabelEncoder()
    df_clean['Sex'] = le.fit_transform(df_clean['Sex'])
    
    # –í–∏–¥–∞–ª—è—î–º–æ —Ä—è–¥–∫–∏ –∑ –ø—Ä–æ–ø—É—â–µ–Ω–∏–º–∏ –∑–Ω–∞—á–µ–Ω–Ω—è–º–∏
    df_clean = df_clean.dropna()
    
    print(f"‚úÖ –î–∞–Ω—ñ –ø—ñ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ! –ó–∞–ª–∏—à–∏–ª–æ—Å—å {len(df_clean)} –∑–∞–ø–∏—Å—ñ–≤")
    print(f"–û–∑–Ω–∞–∫–∏ –¥–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è: Pclass, Sex, Age, SibSp, Parch, Fare")
    print(f"–¶—ñ–ª—å–æ–≤–∞ –∑–º—ñ–Ω–Ω–∞: Survived (0 = –∑–∞–≥–∏–Ω—É–≤, 1 = –≤–∏–∂–∏–≤)\n")
    
    return df_clean, le

def train_model():
    """–ù–∞–≤—á–∞—î –æ–ø—Ç–∏–º–∞–ª—å–Ω—É –º–æ–¥–µ–ª—å —Ç–∞ –∑–±–µ—Ä—ñ–≥–∞—î —ó—ó"""
    print("="*80)
    print("üü¢ –ù–ê–í–ß–ê–ù–ù–Ø –û–ü–¢–ò–ú–ê–õ–¨–ù–û–á –ú–û–î–ï–õ–Ü (GOOD FIT)")
    print("="*80)
    
    # –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö
    df_clean, label_encoder = prepare_data()
    
    # –†–æ–∑–¥—ñ–ª—è—î–º–æ –Ω–∞ –æ–∑–Ω–∞–∫–∏ (X) —Ç–∞ —Ü—ñ–ª—å–æ–≤—É –∑–º—ñ–Ω–Ω—É (y)
    X_full = df_clean.drop('Survived', axis=1)
    y_full = df_clean['Survived']
    
    # –†–æ–∑–¥—ñ–ª—è—î–º–æ –Ω–∞ train —Ç–∞ test (70% train, 30% test)
    X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(
        X_full, y_full, test_size=0.3, random_state=42
    )
    
    print(f"üìä –†–æ–∑–º—ñ—Ä —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω–æ–≥–æ –Ω–∞–±–æ—Ä—É: {len(X_train_full)} –∑–∞–ø–∏—Å—ñ–≤")
    print(f"üìä –†–æ–∑–º—ñ—Ä —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –Ω–∞–±–æ—Ä—É: {len(X_test_full)} –∑–∞–ø–∏—Å—ñ–≤\n")
    
    # –ù–∞–≤—á–∞—î–º–æ –º–æ–¥–µ–ª—å –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ—ó —Å–∫–ª–∞–¥–Ω–æ—Å—Ç—ñ
    print("üîß –ù–∞–≤—á–∞—î–º–æ –º–æ–¥–µ–ª—å...")
    model_goodfit = DecisionTreeClassifier(max_depth=5, min_samples_split=20, random_state=42)
    model_goodfit.fit(X_train_full, y_train_full)
    
    # –ü–µ—Ä–µ–¥–±–∞—á–∞—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
    y_train_pred = model_goodfit.predict(X_train_full)
    y_test_pred = model_goodfit.predict(X_test_full)
    
    # –û–±—á–∏—Å–ª—é—î–º–æ —Ç–æ—á–Ω—ñ—Å—Ç—å
    train_accuracy = accuracy_score(y_train_full, y_train_pred)
    test_accuracy = accuracy_score(y_test_full, y_test_pred)
    
    print("üìà –†–ï–ó–£–õ–¨–¢–ê–¢–ò –ù–ê–í–ß–ê–ù–ù–Ø:")
    print(f"   –¢–æ—á–Ω—ñ—Å—Ç—å –Ω–∞ —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö: {train_accuracy*100:.1f}%")
    print(f"   –¢–æ—á–Ω—ñ—Å—Ç—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö: {test_accuracy*100:.1f}%")
    print(f"   –†—ñ–∑–Ω–∏—Ü—è: {abs(train_accuracy - test_accuracy)*100:.1f}%")
    print("\nüí° –ú–æ–¥–µ–ª—å –û–ü–¢–ò–ú–ê–õ–¨–ù–ê! –í–æ–Ω–∞ –¥–æ–±—Ä–µ –ø—Ä–∞—Ü—é—î –Ω–∞ –æ–±–æ—Ö –Ω–∞–±–æ—Ä–∞—Ö –¥–∞–Ω–∏—Ö.\n")
    
    # –°—Ç–≤–æ—Ä—é—î–º–æ –ø–∞–ø–∫—É –¥–ª—è –º–æ–¥–µ–ª–µ–π, —è–∫—â–æ —ó—ó –Ω–µ–º–∞—î
    os.makedirs('titanic_game/models', exist_ok=True)
    
    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –º–æ–¥–µ–ª—å
    model_path = 'titanic_game/models/titanic_model.pkl'
    with open(model_path, 'wb') as f:
        pickle.dump(model_goodfit, f)
    print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {model_path}")
    
    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ LabelEncoder
    encoder_path = 'titanic_game/models/label_encoder.pkl'
    with open(encoder_path, 'wb') as f:
        pickle.dump(label_encoder, f)
    print(f"‚úÖ LabelEncoder –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {encoder_path}")
    
    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ —Å–µ—Ä–µ–¥–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è –¥–ª—è –∑–∞–ø–æ–≤–Ω–µ–Ω–Ω—è –ø—Ä–æ–ø—É—Å–∫—ñ–≤
    # (–º–æ–∂–µ –∑–Ω–∞–¥–æ–±–∏—Ç–∏—Å—è –¥–ª—è –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω—å)
    feature_stats = {
        'age_median': df_clean['Age'].median(),
        'fare_median': df_clean['Fare'].median(),
    }
    stats_path = 'titanic_game/models/feature_stats.pkl'
    with open(stats_path, 'wb') as f:
        pickle.dump(feature_stats, f)
    print(f"‚úÖ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–∑–Ω–∞–∫ –∑–±–µ—Ä–µ–∂–µ–Ω–∞: {stats_path}")
    
    print("\n" + "="*80)
    print("‚úÖ –ù–ê–í–ß–ê–ù–ù–Ø –ó–ê–í–ï–†–®–ï–ù–û –£–°–ü–Ü–®–ù–û!")
    print("="*80)
    print("\nüí° –ü–æ—Ä–∞–¥–∞: –î–ª—è –Ω–∞–≤—á–∞–ª—å–Ω–æ–≥–æ —Ä–µ–∂–∏–º—É –∑–∞–ø—É—Å—Ç—ñ—Ç—å —Ç–∞–∫–æ–∂ utils.train_all_models()")
    print("   –∞–±–æ –∑–∞–ø—É—Å—Ç—ñ—Ç—å –Ω–∞–≤—á–∞–ª—å–Ω–∏–π —Ä–µ–∂–∏–º –≤ app.py - –≤—ñ–Ω –Ω–∞–≤—á–∏—Ç—å –≤—Å—ñ –º–æ–¥–µ–ª—ñ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ.")
    print("="*80)
    
    return model_goodfit, label_encoder, feature_stats

if __name__ == "__main__":
    train_model()

